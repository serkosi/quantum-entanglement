# Our Project (Name: TBD)

In Quantum Machine Learning (QML) research, classical datasets are often used to benchmark quantum models. Some of the most common classical datasets include: MNIST, Iris, Dogs vs. Cats, and ProteinNet.

These datasets are typically encoded into quantum states using embedding schemes, which map classical data into quantum representations. However, [it is argueable that classical datasets may not lead to quantum advantage and using quantum datasets might be promising](https://arxiv.org/pdf/2109.03400) instead.

Quantum datasets composed of quantum states, rather than transforming classical datasets into quantum data. Specifically, the authors introduced the [**NTangled Dataset**](https://github.com/LSchatzki/NTangled_Datasets), which consists of quantum states with varying levels and types of multipartite entanglement. These states were generated by training a Quantum Neural Network (**QNN**) to produce quantum states with desired entanglement properties. The input states for the **QNN** can be sampled from sets like computational basis states or product states, depending on the experiment.

This approach eliminates the need for embedding classical data into quantum states, focusing entirely on quantum-native datasets.\
Understanding the initial input states is crucial. Here's a breakdown:

1. **Computational Basis States**:

    These are the simplest quantum states, often denoted as $|0\rangle$ and $|1\rangle$ for a single qubit. For multi-qubit systems, they extend to states like $|00\rangle, |01\rangle, |10\rangle, |11\rangle$, and so on.

    They form an orthonormal basis for the Hilbert space of quantum states, meaning any quantum state can be expressed as a linear combination of these basis states.

    These states are non-entangled and are often used as a starting point in quantum algorithms because they are easy to prepare.

2. **Product States**:

    These are states that can be written as the tensor product of individual qubit states. For example, if one qubit is in state $|0\rangle$ and another is in state $|1\rangle$, the combined product state is $|0\rangle \otimes |1\rangle = |01\rangle$.

    Like computational basis states, product states are non-entangled. However, they offer more variety since each qubit can independently be in a superposition of $|0\rangle$ and $|1\rangle$, such as $\alpha|0\rangle + \beta|1\rangle$.

In the paper, the authors mention using these states (they preffered Product States sampling) as input to their **Quantum Neural Network (QNN)**. The **QNN** then transforms these simple, non-entangled states into more complex quantum states with specific entanglement properties, forming the **NTangled dataset**.

## Generating Product States
Algorithmically creating random product states for an **ùëõ-qubit system** is implemented in the [`product_states.py`](product_states.py) file.

Each qubit can be in a random superposition state like $ùõº|0‚ü© + ùõΩ|1‚ü©$, where $|ùõº|^2 + |ùõΩ|^2 = 1$.

1. The **random_qubit_state** function generates a random single-qubit state by choosing random amplitudes and normalizing them.

2. The **generate_product_state** function uses the tensor product (np.kron) to combine single-qubit states into a multi-qubit product state.

3. One can specify the number of qubits (**n_qubits**) to generate the product state.

## Quantum Entanglement

[**Authors' Dataset**](https://github.com/LSchatzki/NTangled_Datasets) consists of quantum states with varying degrees and types of multipartite entanglement.

The repository includes trained weights for three different **ansatzes**:‚Äã
- **Hardware Efficient Ansatz**
- **Strongly Entangling Ansatz**
- **Convolutional Ansatz**

These are provided across various numbers of qubits, depths, and target values of entanglement. The data is available in both Numpy (.npy) and text (.txt) formats.

The dataset contains numerical data (e.g., **entanglement measures**, circuit parameters) that can be treated as features. These features can be directly fed into classical ML algorithms for tasks like classification, regression, or clustering.

By applying classical ML, we can uncover patterns, perform dimensionality reduction, or even predict physical properties that relate to the underlying physics phenomena.

### Approach for a Classical ML Project

1. Data Preprocessing:
    - Load the dataset using NumPy or Pandas.
    - Normalize or standardize features.
    - Perform exploratory data analysis (EDA) to understand correlations and distributions.

2. Feature Engineering:
    - Extract meaningful features from the raw quantum state data.
    - Consider techniques like principal component analysis (**PCA**) to reduce dimensionality.

3. Model Selection:
    - Start with classical methods such as logistic regression, decision trees, or support vector machines.
    - Evaluate models using cross-validation and standard metrics (accuracy, precision, recall).

4. Visualization and Interpretation:
    - Plot feature distributions, decision boundaries, or **PCA** projections to gain insights.
    - Compare results across different **ansatzes** or parameter settings.

