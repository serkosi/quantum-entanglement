# Our Project (Name: TBD)

## Quick Start

To execute the project from the VSCode terminal, follow these steps:

1. **Install Dependencies**:
   - Before running the project, ensure all required dependencies are installed. Run the following command:
     ```sh
     pip install -r requirements.txt
     ```

2. **Run the Script**:
   - Execute any script of your chioce in the project using Python such as:
     ```sh
     python product_states.py  # Contains functions to generate and manipulate product states
     python data_generation.py  # Generates random quantum product states and saves them to a file
     python data_preprocessing.py  # Preprocesses classical or quantum datasets
     python comb_sum.py  # Computes combinations and their sums for quantum state analysis
     python entanglement_analysis.py  # Analyzes quantum entanglement in datasets
     python train_qnn.py  # Trains a Quantum Neural Network (QNN)
     ```

3. **View the Output**:
   - The output of the script will be displayed in the terminal. Any generated files (e.g., data files) will be saved in the appropriate directories as specified in the code.

## Project

In Quantum Machine Learning (QML) research, classical datasets are often used to benchmark quantum models. Some of the most common classical datasets include: MNIST, Iris, Dogs vs. Cats, and ProteinNet.

These datasets are typically encoded into quantum states using embedding schemes, which map classical data into quantum representations. However, [it is argueable that classical datasets may not lead to quantum advantage and using quantum datasets might be promising](https://arxiv.org/pdf/2109.03400) instead.

Quantum datasets composed of quantum states, rather than transforming classical datasets into quantum data. Specifically, the authors introduced the [**NTangled Dataset**](https://github.com/LSchatzki/NTangled_Datasets), which consists of quantum states with varying levels and types of multipartite entanglement. These states were generated by training a Quantum Neural Network (**QNN**) to produce quantum states with desired entanglement properties. The input states for the **QNN** can be sampled from sets like computational basis states or product states, depending on the experiment.

This approach eliminates the need for embedding classical data into quantum states, focusing entirely on quantum-native datasets.\
Understanding the initial input states is crucial. Here's a breakdown:

1. **Computational Basis States**:

    These are the simplest quantum states, often denoted as $|0\rangle$ and $|1\rangle$ for a single qubit. For multi-qubit systems, they extend to states like $|00\rangle, |01\rangle, |10\rangle, |11\rangle$, and so on.

    They form an orthonormal basis for the Hilbert space of quantum states, meaning any quantum state can be expressed as a linear combination of these basis states.

    These states are non-entangled and are often used as a starting point in quantum algorithms because they are easy to prepare.

2. **Product States**:

    These are states that can be written as the tensor product of individual qubit states. For example, if one qubit is in state $|0\rangle$ and another is in state $|1\rangle$, the combined product state is $|0\rangle \otimes |1\rangle = |01\rangle$.

    Like computational basis states, product states are non-entangled. However, they offer more variety since each qubit can independently be in a superposition of $|0\rangle$ and $|1\rangle$, such as $\alpha|0\rangle + \beta|1\rangle$.

In the paper, the authors mention using these states (they preffered Product States sampling) as input to their **Quantum Neural Network (QNN)**. The **QNN** then transforms these simple, non-entangled states into more complex quantum states with specific entanglement properties, forming the **NTangled dataset**.

### Generating Product States
Algorithmically creating random product states for an **ùëõ-qubit system** is implemented in the [`product_states.py`](product_states.py) file.

Each qubit can be in a random superposition state like $ùõº|0‚ü© + ùõΩ|1‚ü©$, where $|ùõº|^2 + |ùõΩ|^2 = 1$.

1. The **random_qubit_state** function generates a random single-qubit state by choosing random amplitudes and normalizing them.

2. The **generate_product_state** function uses the tensor product (np.kron) to combine single-qubit states into a multi-qubit product state.

3. One can specify the number of qubits (**n_qubits**) to generate the product state.

The [`data_generation.py`](./data_generation.py) script is responsible for generating random quantum product states and saving them to a file. Here's how it works:

1. **Imports the `product_states` Module**:
   - The script uses the `generate_product_state` function from the [`product_states.py`](product_states.py) file to create random product states.

2. **Defines Output File and Parameters**:
   - The generated product states are saved to `data/product_states.txt`.
   - The script generates 10 product states, each consisting of 3 qubits.

3. **Generates and Saves Product States**:
   - For each product state, the script:
     - Calls `generate_product_state` to create a random product state.
     - Writes the state to the output file in a space-separated format.

4. **Prints a Confirmation Message**:
   - After generating and saving the states, the script prints a message indicating the number of states written and the file location.

This functionality is useful for creating quantum datasets composed of product states, which can be used in quantum computing experiments or simulations.

### Quantum Entanglement

[**Authors' Dataset**](https://github.com/LSchatzki/NTangled_Datasets) consists of quantum states with varying degrees and types of multipartite entanglement.

The repository includes trained weights for three different **ansatzes**:‚Äã
- **Hardware Efficient Ansatz**
- **Strongly Entangling Ansatz**
- **Convolutional Ansatz**

These are provided across various numbers of qubits, depths, and target values of entanglement. The data is available in both Numpy (.npy) and text (.txt) formats.

The dataset contains numerical data (e.g., **entanglement measures**, circuit parameters) that can be treated as features. These features can be directly fed into classical ML algorithms for tasks like classification, regression, or clustering.

By applying classical ML, we can uncover patterns, perform dimensionality reduction, or even predict physical properties that relate to the underlying physics phenomena.

## Approach for a Classical ML Project

1. Data Preprocessing:
    - Load the dataset using NumPy or Pandas.
    - Normalize or standardize features.
    - Perform exploratory data analysis (EDA) to understand correlations and distributions.

2. Feature Engineering:
    - Extract meaningful features from the raw quantum state data.
    - Consider techniques like principal component analysis (**PCA**) to reduce dimensionality.

3. Model Selection:
    - Start with classical methods such as logistic regression, decision trees, or support vector machines.
    - Evaluate models using cross-validation and standard metrics (accuracy, precision, recall).

4. Visualization and Interpretation:
    - Plot feature distributions, decision boundaries, or **PCA** projections to gain insights.
    - Compare results across different **ansatzes** or parameter settings.

## Some Outlook Points to Shape the Project

Many researchers in the field believe that quantum machine learning (QML) methods have the potential to perform significantly better when modeling and analyzing complex systems.

1. **Exploitation of Quantum Phenomena** 
    
    QML methods are designed based on principles like superposition, entanglement, and interference. These quantum properties allow QML algorithms to represent, encode, and process information in a feature space that could naturally capture the rich, nontrivial correlations found in complex physical, chemical, and even biological systems. The idea is that, for data that stem from or resemble quantum phenomena, a quantum-inspired feature map can capture the subtle interactions and structure much more efficiently than classical representations.

2. **Enhanced Representational Power** 
    
    Conventional machine learning methods typically represent data in a high-dimensional classical space, but they are limited by the type of correlations they can efficiently handle. In contrast, QML methods‚Äîsuch as those that utilize quantum kernel methods or quantum neural networks‚Äîcan sometimes embed data into exponentially large Hilbert spaces. This embedding can potentially offer a compressed yet highly expressive representation, especially useful when the underlying system is itself complex. If the essential structure of the data lies in a low-dimensional subspace of a much larger quantum space, then a QML approach might achieve better generalization with fewer samples.

3. **Addressing Intractable Problems** 
    
    Complex systems, by nature, often involve exponentially many configurations or interactions. Traditional classical methods can be overwhelmed by this complexity, leading to issues like intractable optimization problems or an explosion in computational resources. Quantum machine learning methods are seen as promising in this regard because they can‚Äîin theory‚Äîhandle certain classes of problems more naturally. For instance, quantum algorithms have been shown to offer advantages in simulating quantum many-body systems or solving optimization problems that are otherwise extremely challenging for classical computers.

4. **Emerging Theoretical and Numerical Evidence** 
    
    The numerical studies described in the supplement illustrate that by carefully managing factors like model complexity, effective dimensionality, and regularization, one can achieve prediction error bounds that scale favorably with the amount of data. These results suggest that when classical data is encoded into quantum states using circuits like separable rotations or IQP-type embeddings, the learning structure might inherently align with the complex nature of the data, potentially providing a computational edge over classical methods. Although these results are primarily theoretical and validated through simulations, they fuel optimism about the prospect for QML methods to excel in practical scenarios involving complex systems.

5. **Practical Outlook and Challenges** 

    While the theoretical foundations and initial numerical experiments are promising, it‚Äôs important to note that QML is still in its early stages. The quantum advantage for machine learning on complex systems remains an active topic of research, with practical demonstrations reliant on the refinement of quantum hardware and error-correction methods. Nonetheless, the potential to capture and exploit complex correlations in data that are inherently quantum-mechanical or derived from highly non-linear processes keeps the research community excited.

There is a growing optimism that the methods inspired by quantum physics can yield more efficient and powerful algorithms when dealing with complex systems. These methods are being developed not only to match classical performance but also to surpass it in regimes where the structure of the data benefits from a quantum-mechanical perspective. Researchers envision applications ranging from quantum chemistry and drug discovery to optimization in finance and logistics, where classical methods currently struggle due to the sheer complexity of the underlying processes.